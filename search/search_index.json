{
    "docs": [
        {
            "location": "/",
            "text": "git-commit-ectomy\n\n\nPerform a git-commit-ectomy to forever remove problematic commits from your repo history.\n\n\nThis uses the \ngit-forget-blob.sh\n script from @nachoparker.\n\n\n\n\nwhat is this\n\n\nThis page covers how to perform a git-commit-ectomy.\nThis is a procedure that removes problematic files or\ncommits from your repository history. \n\n\nFor example, suppose the intern adds and commits a 1 GB \nCSV file to your repository. After profusely apologizing,\nthe intern removes the 1 GB file, but the damage is done,\nand the 1 GB file will forever bloat \n.git\n.\n\n\nEnter the git surgeon. A git surgeon can remove such \nproblematic commits and get the commit history back in \nshape.\n\n\nVisit the Git College of Surgery on Github\n\n\nthe procedure\n\n\nThis surgical procedure can happen one of three ways:\n\n\n\n\n\n\nGit-Commit-Ectomy the Easy Way: \nSingle Branch\n\n\n\n\n\n\nComplications: \nDealing with Branches\n\n\n\n\n\n\nGit-Commit-Ectomy the Hard Way: \nCherry Picking\n\n\n\n\n\n\nOh F&!k: \nPlease Send Backup\n\n\n\n\n\n\nconsult with your doctor\n\n\nYou should consult with your doctor to determine if a \ngit-commit-ectomy is right for your repository.\n\n\nThis one-liner lists the 40 largest files in the repo\n(modify the \ntail\n line to change the number):\n\n\n$ git rev-list --all --objects | \\\n     sed -n $(git rev-list --objects --all | \\\n     cut -f1 -d' ' | \\\n     git cat-file --batch-check | \\\n     grep blob | \\\n     sort -n -k 3 | \\\n     \\\n     tail -n40 | \\\n     \\\n     while read hash type size; do\n          echo -n \"-e s/$hash/$size/p \";\n     done) | \\\n     sort -n -r -k1",
            "title": "Index"
        },
        {
            "location": "/#git-commit-ectomy",
            "text": "Perform a git-commit-ectomy to forever remove problematic commits from your repo history.  This uses the  git-forget-blob.sh  script from @nachoparker.",
            "title": "git-commit-ectomy"
        },
        {
            "location": "/#what-is-this",
            "text": "This page covers how to perform a git-commit-ectomy.\nThis is a procedure that removes problematic files or\ncommits from your repository history.   For example, suppose the intern adds and commits a 1 GB \nCSV file to your repository. After profusely apologizing,\nthe intern removes the 1 GB file, but the damage is done,\nand the 1 GB file will forever bloat  .git .  Enter the git surgeon. A git surgeon can remove such \nproblematic commits and get the commit history back in \nshape.  Visit the Git College of Surgery on Github",
            "title": "what is this"
        },
        {
            "location": "/#the-procedure",
            "text": "This surgical procedure can happen one of three ways:    Git-Commit-Ectomy the Easy Way:  Single Branch    Complications:  Dealing with Branches    Git-Commit-Ectomy the Hard Way:  Cherry Picking    Oh F&!k:  Please Send Backup",
            "title": "the procedure"
        },
        {
            "location": "/#consult-with-your-doctor",
            "text": "You should consult with your doctor to determine if a \ngit-commit-ectomy is right for your repository.  This one-liner lists the 40 largest files in the repo\n(modify the  tail  line to change the number):  $ git rev-list --all --objects | \\\n     sed -n $(git rev-list --objects --all | \\\n     cut -f1 -d' ' | \\\n     git cat-file --batch-check | \\\n     grep blob | \\\n     sort -n -k 3 | \\\n     \\\n     tail -n40 | \\\n     \\\n     while read hash type size; do\n          echo -n \"-e s/$hash/$size/p \";\n     done) | \\\n     sort -n -r -k1",
            "title": "consult with your doctor"
        },
        {
            "location": "/easy/",
            "text": "requirements\n\n\nThis guide utilizes GNU xargs. \nYou should run it on Linux, \nor use Homebrew's gxargs if \non a Mac.\n\n\nconsult with your doctor\n\n\nYou should consult with your doctor to determine if a \ngit-commit-ectomy is right for you.\n\n\nThis one-liner lists the 40 largest files in the repo\n(modify the \ntail\n line to change the number):\n\n\n$ git rev-list --all --objects | \\\n     sed -n $(git rev-list --objects --all | \\\n     cut -f1 -d' ' | \\\n     git cat-file --batch-check | \\\n     grep blob | \\\n     sort -n -k 3 | \\\n     \\\n     tail -n40 | \\\n     \\\n     while read hash type size; do\n          echo -n \"-e s/$hash/$size/p \";\n     done) | \\\n     sort -n -r -k1 \n\n\n\n\nWhen you're ready to perform the surgery, append \ntwo more lines to get the filenames only, which is what \n\ngit-forget-blob.sh\n needs:\n\n\n$ git rev-list --all --objects | \\\n     sed -n $(git rev-list --objects --all | \\\n     cut -f1 -d' ' | \\\n     git cat-file --batch-check | \\\n     grep blob | \\\n     sort -n -k 3 | \\\n     \\\n     tail -n40 | \\\n     \\\n     while read hash type size; do\n          echo -n \"-e s/$hash/$size/p \";\n     done) | \\\n     sort -n -k1 | \\\n     cut -f 2 -d' ' | \\\n     xargs -n1 basename \n\n\n\n\ndemo surgery: setup\n\n\nClone an example repo for performing surgery:\n\n\n$ git clone https://github.com/charlesreid1/git-commit-ectomy-example\n\n\n\n\nhow to make a fat file\n\n\nUse \ndd\n to create files by assembling \na specified number of bits.\nFor example, to create a 10 MB file:\n\n\n$ dd if=/dev/urandom of=my_big_fat_file bs=1048576 count=10\n\n\n\n\nImportant:\n You must use \n/dev/urandom\n with a non-zero block size.\nIf you use \n/dev/zeros\n then each file will be identical and git \nwill not store them separately. Then your surgery will go very badly.\n\n\nNote:\n \n1048576 = 2^20\n bytes comes from\n1 KB = \n2^10\n bytes, and 1 MB = \n2^10\n KB, \nfor a total of \n2^20\n bytes per megabyte.\n\n\ncount = 10 means we make 10 1mb blocks.\n\n\nmake several fat files\n\n\nCrank them out. bat cat dat fat rat!\n\n\ndd if=/dev/urandom of=bat bs=1048576 count=10\ndd if=/dev/urandom of=cat bs=1048576 count=10\ndd if=/dev/urandom of=dat bs=1048576 count=10\ndd if=/dev/urandom of=fat bs=1048576 count=10\ndd if=/dev/urandom of=rat bs=1048576 count=10\n\n\n\n\nMake sure they are the correct size:\n\n\n$ ls -lhg\n-rw-r--r--   1 staff    10M Apr 10 18:30 bat\n-rw-r--r--   1 staff    10M Apr 10 18:30 cat\n-rw-r--r--   1 staff    10M Apr 10 18:30 dat\n-rw-r--r--   1 staff    10M Apr 10 18:30 fat\n-rw-r--r--   1 staff    10M Apr 10 18:30 rat\n\n\n\n\nAlso make sure they are unique (hence \n/dev/random\n and not \n/dev/zero\n):\n\n\n$ for i in `/bin/ls -1 *at`; do\n    md5 ${i}\ndone\n\nMD5 (bat) = 140c7d1e5a12c0eb2fefd5529250a280\nMD5 (cat) = 9345ca4033c7e42fb009e3b8014570dc\nMD5 (dat) = fadc3114fe9a70f688eba0db4e0dc7a9\nMD5 (fat) = 39e98200043e438f9070369989b2d964\nMD5 (rat) = 77b1c3077041078fd1f371b1bb7dd6e4\n\n\n\n\ncommit files\n\n\nAdd the files to the repo in \nseparate commits\n:\n\n\nfor item in bat cat dat fat rat; do\n    git add ${item} && git commit ${item} -m \"Adding ${item}\"\ndone\n\ngit push origin master\n\n\n\n\nI also added two dummy files \nfoo.txt\n and \nbar.txt\n \nto illustrate the impact of the surgery on \ncommit history.\n\n\nNow you should see everything in the commit history:\n\n\n\n\nLocally in git log:\n\n\n$ git log --oneline\nfd76938 Add bar.txt\n8a86eaf Add foo.txt\nc50a272 Adding rat\n423ede3 Adding fat\nb56c10b Adding dat\nbeb8b4f Adding cat\n84d894e Adding bat\n\n\n\n\ndemo surgery: procedure\n\n\nprepare tools\n\n\nUse \ngit-forget-blob.sh\n\nto forget the blob. Start by downloading it:\n\n\n$ wget https://tinyurl.com/git-forget-blob-mac-sh -O git-forget-blob.sh\n$ chmod +x git-forget-blob.sh\n\n\n\n\nThis script will detect if you are on a Mac,\nand if so, will use the GNU \ngxargs\n instead of \nthe BSD \nxargs\n. This requires GNU tools to be \ninstalled via Homebrew:\n\n\nbrew install gnu-sed\n\n\n\n\nOptional: can use \n--with-default-names\n to overwrite\nBSD versions with GNU versions.\n\n\nbrew install gnu-sed --with-default-names\n\n\n\n\nTo use the script:\n\n\n./git-forget-blob.sh <name-of-file>\n\n\n\n\ngit rm\n\n\nStart by checking the size of the repo:\n\n\n$ du -hs .git\n 50M    .git\n\n\n\n\nNow remove \ndat\n using \ngit rm\n:\n\n\n$ git rm dat\n$ git commit dat -m 'Removing dat'\n$ git push origin master\n\n\n\n\nThis, of course, does not change the size of the repo.\nIf we clone a fresh copy from Github, the size of the \nrepo is still the same:\n\n\n$ du -hs .git\n 50M    .git\n\n\n\n\nGit is cursed with perfect memory, and will not\nforget a large file that's been added to the repo.\n\n\ngit forget blob\n\n\nWe use \ngit-forget-blob.sh\n to permanenty remove \n\ndat\n from the repo history and rewrite all commits\nsince the file was added:\n\n\n$ ./git-forget-blob.sh dat\nCounting objects: 23, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (22/22), done.\nWriting objects: 100% (23/23), done.\nTotal 23 (delta 6), reused 0 (delta 0)\nRewrite 84d894e39d63bbea54a7b8d3d1c85c588adff7ae (1/8) (0 seconds pRewrite beb8b4f2fbb257c0d6098620de7a8df5d7dd74ed (2/8) (0 seconds pRewrite b56c10bafeb95eece9880aa1a52cfc3e4e99045e (3/8) (0 seconds passed, remaining 0 predicted)    rm 'dat'\nRewrite 423ede37f4d75dbb7a1b8020c561c4d7a926a97f (4/8) (0 seconds passed, remaining 0 predicted)    rm 'dat'\nRewrite c50a2724f6d722002133b04b0f63f271b861ff9c (5/8) (0 seconds passed, remaining 0 predicted)    rm 'dat'\nRewrite 8a86eafbb5b669120fa1073cfa7567bbebf2fb2e (6/8) (0 seconds passed, remaining 0 predicted)    rm 'dat'\nRewrite fd769386dcd32354bad57e8eb057ae8adb2b3c9b (7/8) (0 seconds passed, remaining 0 predicted)    rm 'dat'\nRewrite d0587c525a5f64d02b1cb46c04261ab285c907f9 (8/8) (0 seconds passed, remaining 0 predicted)\nRef 'refs/heads/master' was rewritten\nCounting objects: 20, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (19/19), done.\nWriting objects: 100% (20/20), done.\nTotal 20 (delta 6), reused 8 (delta 0)\n\n\n\n\nNow check if it worked:\n\n\n$ du -hs .git\n 40M    .git\n\n\n\n\nSuccess!\n\n\nhow it worked\n\n\nIf we check the git log we can see what happened - all commits involving \ndat\n were rewritten. Because git uses the prior commit's hash to make the next commit's hash, \nwe will rewrite every commit since the first time \ndat\n was added to the repo\n:\n\n\nNew log:\n\n\n$ git log --oneline\n3c10144 Removing dat\n6f7b8f2 Add bar.txt\n3f70da5 Add foo.txt\n5406c1a Adding rat\ndf458d0 Adding fat\n5f6e932 Adding dat\nbeb8b4f Adding cat\n84d894e Adding bat\n\n\n\n\nCompare to the old log:\n\n\n$ git log --oneline\nd0587c5 Removing dat\nfd76938 Add bar.txt\n8a86eaf Add foo.txt\nc50a272 Adding rat\n423ede3 Adding fat\nb56c10b Adding dat\nbeb8b4f Adding cat\n84d894e Adding bat\n\n\n\n\nNote that the \"Add cat\" commit IDs are identical, \nbut every commit after \ndat\n was added to the repo is changed. \n\n\nThis is because each commit ID is computed using the hash of the prior commit, \nso if we change one commit ID in history, we change all subsequent commit IDs.\n\n\nstitch the patient back up\n\n\nOf course, for surgeons, as for airline pilots,\nif the last step is screwed up, nothing else counts.\n\n\nWe asked git to forget a file, which it did, \nbut that required modifying commits in the \ngit history, which required re-calculating\ncommit hashes.\n\n\nAt this point, we have two separate, parallel \n\nmaster\n branches that split when our \nfile \ndat\n was added to the repo.\n\n\nIf we simply push our branch to the Github remote,\nwe will have a huge headache: every commit will have \na duplicate, the old branch and the new branch,\nand will show up side-by-side.\n\n\nTo do this correctly, we need to use the force\nwhen we push:\n\n\n$ git push origin master --force\n\n\n\n\nThis will ensure that Github does not keep duplicate\ncopies of all commits.\n\n\nHere is a screenshot of the repo on github before \nwe ran \ngit-forget-blob\n:\n\n\n\n\nAnd a screenshot of the repo after:\n\n\n\n\ntips for surgery\n\n\nPass the filename \nonly\n to \ngit-forget-blob.sh\n.\n\n\nThis is very important!!!\n\n\nThe long one-liner in the \"Consult with your Doctor\" section\nwill list the largest files in the repository, with the relative\npath to that file in the repository.\n\n\nThe git forget blob script needs the name of the file only,\nwithout a path. \n\n\nIf you pass it a filename with a path in front, it will not\npermanently remove that file from the git repo, but it will \nstill take a really long time to go through each commit in the\nrepo history.\n\n\nIf you are running \ngit-forget-blob.sh\n and the size of the \n\n.git\n folder is not going down, this is probably what's \ngoing on.\n\n\nSize up your patient.\n\n\nThis one-liner lists the 40 largest files in the repo\n(modify the tail line to change the number):\n\n\n$ git rev-list --all --objects | \\\n     sed -n $(git rev-list --objects --all | \\\n     cut -f1 -d' ' | \\\n     git cat-file --batch-check | \\\n     grep blob | \\\n     sort -n -k 3 | \\\n     \\\n     tail -n40 | \\\n     \\\n     while read hash type size; do\n          echo -n \"-e s/$hash/$size/p \";\n     done) | \\\n     sort -n -k1 | \\\n     cut -f 2 -d' ' | \\\n     xargs -n1 basename \n\n\n\n\nNote that this extracts the filename only, which is what\n\ngit-forget-blob.sh\n needs.\n\n\nGet your patient some insurance.\n \n\n\nBack up any files you want to remove but keep.\n\n\nMake sure you specify file names without paths.\n \n\n\nThe \ngit-forget-blob.sh\n script uses blobs in the \n.git\n directory.\nThese do not contain any relative path information about where in the \nrepository a particular file lives. So you should do this:\n\n\n./git-forget-blob.sh super_huge.file\n\n\n\n\nnot this:\n\n\n./git-forget-blob.sh data/my_project/phase_1/proprietary/super_huge.file  # WRONG",
            "title": "Git-Commit-Ectomy the Easy Way: Single Branch"
        },
        {
            "location": "/easy/#requirements",
            "text": "This guide utilizes GNU xargs. \nYou should run it on Linux, \nor use Homebrew's gxargs if \non a Mac.",
            "title": "requirements"
        },
        {
            "location": "/easy/#consult-with-your-doctor",
            "text": "You should consult with your doctor to determine if a \ngit-commit-ectomy is right for you.  This one-liner lists the 40 largest files in the repo\n(modify the  tail  line to change the number):  $ git rev-list --all --objects | \\\n     sed -n $(git rev-list --objects --all | \\\n     cut -f1 -d' ' | \\\n     git cat-file --batch-check | \\\n     grep blob | \\\n     sort -n -k 3 | \\\n     \\\n     tail -n40 | \\\n     \\\n     while read hash type size; do\n          echo -n \"-e s/$hash/$size/p \";\n     done) | \\\n     sort -n -r -k1   When you're ready to perform the surgery, append \ntwo more lines to get the filenames only, which is what  git-forget-blob.sh  needs:  $ git rev-list --all --objects | \\\n     sed -n $(git rev-list --objects --all | \\\n     cut -f1 -d' ' | \\\n     git cat-file --batch-check | \\\n     grep blob | \\\n     sort -n -k 3 | \\\n     \\\n     tail -n40 | \\\n     \\\n     while read hash type size; do\n          echo -n \"-e s/$hash/$size/p \";\n     done) | \\\n     sort -n -k1 | \\\n     cut -f 2 -d' ' | \\\n     xargs -n1 basename",
            "title": "consult with your doctor"
        },
        {
            "location": "/easy/#demo-surgery-setup",
            "text": "Clone an example repo for performing surgery:  $ git clone https://github.com/charlesreid1/git-commit-ectomy-example",
            "title": "demo surgery: setup"
        },
        {
            "location": "/easy/#how-to-make-a-fat-file",
            "text": "Use  dd  to create files by assembling \na specified number of bits.\nFor example, to create a 10 MB file:  $ dd if=/dev/urandom of=my_big_fat_file bs=1048576 count=10  Important:  You must use  /dev/urandom  with a non-zero block size.\nIf you use  /dev/zeros  then each file will be identical and git \nwill not store them separately. Then your surgery will go very badly.  Note:   1048576 = 2^20  bytes comes from\n1 KB =  2^10  bytes, and 1 MB =  2^10  KB, \nfor a total of  2^20  bytes per megabyte.  count = 10 means we make 10 1mb blocks.",
            "title": "how to make a fat file"
        },
        {
            "location": "/easy/#make-several-fat-files",
            "text": "Crank them out. bat cat dat fat rat!  dd if=/dev/urandom of=bat bs=1048576 count=10\ndd if=/dev/urandom of=cat bs=1048576 count=10\ndd if=/dev/urandom of=dat bs=1048576 count=10\ndd if=/dev/urandom of=fat bs=1048576 count=10\ndd if=/dev/urandom of=rat bs=1048576 count=10  Make sure they are the correct size:  $ ls -lhg\n-rw-r--r--   1 staff    10M Apr 10 18:30 bat\n-rw-r--r--   1 staff    10M Apr 10 18:30 cat\n-rw-r--r--   1 staff    10M Apr 10 18:30 dat\n-rw-r--r--   1 staff    10M Apr 10 18:30 fat\n-rw-r--r--   1 staff    10M Apr 10 18:30 rat  Also make sure they are unique (hence  /dev/random  and not  /dev/zero ):  $ for i in `/bin/ls -1 *at`; do\n    md5 ${i}\ndone\n\nMD5 (bat) = 140c7d1e5a12c0eb2fefd5529250a280\nMD5 (cat) = 9345ca4033c7e42fb009e3b8014570dc\nMD5 (dat) = fadc3114fe9a70f688eba0db4e0dc7a9\nMD5 (fat) = 39e98200043e438f9070369989b2d964\nMD5 (rat) = 77b1c3077041078fd1f371b1bb7dd6e4",
            "title": "make several fat files"
        },
        {
            "location": "/easy/#commit-files",
            "text": "Add the files to the repo in  separate commits :  for item in bat cat dat fat rat; do\n    git add ${item} && git commit ${item} -m \"Adding ${item}\"\ndone\n\ngit push origin master  I also added two dummy files  foo.txt  and  bar.txt  \nto illustrate the impact of the surgery on \ncommit history.  Now you should see everything in the commit history:   Locally in git log:  $ git log --oneline\nfd76938 Add bar.txt\n8a86eaf Add foo.txt\nc50a272 Adding rat\n423ede3 Adding fat\nb56c10b Adding dat\nbeb8b4f Adding cat\n84d894e Adding bat",
            "title": "commit files"
        },
        {
            "location": "/easy/#demo-surgery-procedure",
            "text": "",
            "title": "demo surgery: procedure"
        },
        {
            "location": "/easy/#prepare-tools",
            "text": "Use  git-forget-blob.sh \nto forget the blob. Start by downloading it:  $ wget https://tinyurl.com/git-forget-blob-mac-sh -O git-forget-blob.sh\n$ chmod +x git-forget-blob.sh  This script will detect if you are on a Mac,\nand if so, will use the GNU  gxargs  instead of \nthe BSD  xargs . This requires GNU tools to be \ninstalled via Homebrew:  brew install gnu-sed  Optional: can use  --with-default-names  to overwrite\nBSD versions with GNU versions.  brew install gnu-sed --with-default-names  To use the script:  ./git-forget-blob.sh <name-of-file>",
            "title": "prepare tools"
        },
        {
            "location": "/easy/#git-rm",
            "text": "Start by checking the size of the repo:  $ du -hs .git\n 50M    .git  Now remove  dat  using  git rm :  $ git rm dat\n$ git commit dat -m 'Removing dat'\n$ git push origin master  This, of course, does not change the size of the repo.\nIf we clone a fresh copy from Github, the size of the \nrepo is still the same:  $ du -hs .git\n 50M    .git  Git is cursed with perfect memory, and will not\nforget a large file that's been added to the repo.",
            "title": "git rm"
        },
        {
            "location": "/easy/#git-forget-blob",
            "text": "We use  git-forget-blob.sh  to permanenty remove  dat  from the repo history and rewrite all commits\nsince the file was added:  $ ./git-forget-blob.sh dat\nCounting objects: 23, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (22/22), done.\nWriting objects: 100% (23/23), done.\nTotal 23 (delta 6), reused 0 (delta 0)\nRewrite 84d894e39d63bbea54a7b8d3d1c85c588adff7ae (1/8) (0 seconds pRewrite beb8b4f2fbb257c0d6098620de7a8df5d7dd74ed (2/8) (0 seconds pRewrite b56c10bafeb95eece9880aa1a52cfc3e4e99045e (3/8) (0 seconds passed, remaining 0 predicted)    rm 'dat'\nRewrite 423ede37f4d75dbb7a1b8020c561c4d7a926a97f (4/8) (0 seconds passed, remaining 0 predicted)    rm 'dat'\nRewrite c50a2724f6d722002133b04b0f63f271b861ff9c (5/8) (0 seconds passed, remaining 0 predicted)    rm 'dat'\nRewrite 8a86eafbb5b669120fa1073cfa7567bbebf2fb2e (6/8) (0 seconds passed, remaining 0 predicted)    rm 'dat'\nRewrite fd769386dcd32354bad57e8eb057ae8adb2b3c9b (7/8) (0 seconds passed, remaining 0 predicted)    rm 'dat'\nRewrite d0587c525a5f64d02b1cb46c04261ab285c907f9 (8/8) (0 seconds passed, remaining 0 predicted)\nRef 'refs/heads/master' was rewritten\nCounting objects: 20, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (19/19), done.\nWriting objects: 100% (20/20), done.\nTotal 20 (delta 6), reused 8 (delta 0)  Now check if it worked:  $ du -hs .git\n 40M    .git  Success!",
            "title": "git forget blob"
        },
        {
            "location": "/easy/#how-it-worked",
            "text": "If we check the git log we can see what happened - all commits involving  dat  were rewritten. Because git uses the prior commit's hash to make the next commit's hash,  we will rewrite every commit since the first time  dat  was added to the repo :  New log:  $ git log --oneline\n3c10144 Removing dat\n6f7b8f2 Add bar.txt\n3f70da5 Add foo.txt\n5406c1a Adding rat\ndf458d0 Adding fat\n5f6e932 Adding dat\nbeb8b4f Adding cat\n84d894e Adding bat  Compare to the old log:  $ git log --oneline\nd0587c5 Removing dat\nfd76938 Add bar.txt\n8a86eaf Add foo.txt\nc50a272 Adding rat\n423ede3 Adding fat\nb56c10b Adding dat\nbeb8b4f Adding cat\n84d894e Adding bat  Note that the \"Add cat\" commit IDs are identical, \nbut every commit after  dat  was added to the repo is changed.   This is because each commit ID is computed using the hash of the prior commit, \nso if we change one commit ID in history, we change all subsequent commit IDs.",
            "title": "how it worked"
        },
        {
            "location": "/easy/#stitch-the-patient-back-up",
            "text": "Of course, for surgeons, as for airline pilots,\nif the last step is screwed up, nothing else counts.  We asked git to forget a file, which it did, \nbut that required modifying commits in the \ngit history, which required re-calculating\ncommit hashes.  At this point, we have two separate, parallel  master  branches that split when our \nfile  dat  was added to the repo.  If we simply push our branch to the Github remote,\nwe will have a huge headache: every commit will have \na duplicate, the old branch and the new branch,\nand will show up side-by-side.  To do this correctly, we need to use the force\nwhen we push:  $ git push origin master --force  This will ensure that Github does not keep duplicate\ncopies of all commits.  Here is a screenshot of the repo on github before \nwe ran  git-forget-blob :   And a screenshot of the repo after:",
            "title": "stitch the patient back up"
        },
        {
            "location": "/easy/#tips-for-surgery",
            "text": "Pass the filename  only  to  git-forget-blob.sh .  This is very important!!!  The long one-liner in the \"Consult with your Doctor\" section\nwill list the largest files in the repository, with the relative\npath to that file in the repository.  The git forget blob script needs the name of the file only,\nwithout a path.   If you pass it a filename with a path in front, it will not\npermanently remove that file from the git repo, but it will \nstill take a really long time to go through each commit in the\nrepo history.  If you are running  git-forget-blob.sh  and the size of the  .git  folder is not going down, this is probably what's \ngoing on.  Size up your patient.  This one-liner lists the 40 largest files in the repo\n(modify the tail line to change the number):  $ git rev-list --all --objects | \\\n     sed -n $(git rev-list --objects --all | \\\n     cut -f1 -d' ' | \\\n     git cat-file --batch-check | \\\n     grep blob | \\\n     sort -n -k 3 | \\\n     \\\n     tail -n40 | \\\n     \\\n     while read hash type size; do\n          echo -n \"-e s/$hash/$size/p \";\n     done) | \\\n     sort -n -k1 | \\\n     cut -f 2 -d' ' | \\\n     xargs -n1 basename   Note that this extracts the filename only, which is what git-forget-blob.sh  needs.  Get your patient some insurance.    Back up any files you want to remove but keep.  Make sure you specify file names without paths.    The  git-forget-blob.sh  script uses blobs in the  .git  directory.\nThese do not contain any relative path information about where in the \nrepository a particular file lives. So you should do this:  ./git-forget-blob.sh super_huge.file  not this:  ./git-forget-blob.sh data/my_project/phase_1/proprietary/super_huge.file  # WRONG",
            "title": "tips for surgery"
        },
        {
            "location": "/branches/",
            "text": "Dealing with Branches\n\n\n(work in progress)",
            "title": "Complications: Dealing with Branches"
        },
        {
            "location": "/branches/#dealing-with-branches",
            "text": "(work in progress)",
            "title": "Dealing with Branches"
        },
        {
            "location": "/cherrypicking/",
            "text": "A Git-Commit-Ectomy the Hard Way: Cherry-Picking\n\n\n(work in progress)",
            "title": "Git-Commit-Ectomy the Hard Way: Cherry Picking"
        },
        {
            "location": "/cherrypicking/#a-git-commit-ectomy-the-hard-way-cherry-picking",
            "text": "(work in progress)",
            "title": "A Git-Commit-Ectomy the Hard Way: Cherry-Picking"
        },
        {
            "location": "/ohfk/",
            "text": "Oh F&!k: Please Send Backup\n\n\nWhen you use the single-branch procedure\ninstead of the multi-branch procedure...\nthis is what happens.\n\n\nPossible complications to all of this \ninclude:\n\n\n\n\n\n\nClueless individuals who do not\n    follow basic instructions and continue to push\n    old versions of the repo, which can be proactively\n    addressed by branch protection but sometimes\n    must also be retroactively dealt with; \n\n\n\n\n\n\nAccidentally carrying out the procedure multiple times,\n    resulting in 2, 3, 4, even 5 copies of each commit,\n    and the duplicate commits simply refuse to die\n\n\n\n\n\n\nA confusing, tangled, messy commit history that is\n    completely uninterpretable\n\n\n\n\n\n\nthe first case\n\n\nIn the first case, start by turning on branch protection,\nthen clone a fresh copy of the repository (complete with\nall the duplicate commits)\n\n\nthe second case\n\n\nIn the second case, find the branch you want to keep,\nthen rebase or cherry pick any missing commits onto it.\nNow remove all the other branches. If these remote branches\nare not being removed, make sure you have your syntax right,\nand make sure you're using the \n--force\n command.\n\n\ngit push remote_name :branch_to_delete\n\n\n\n\nFor example, if I want to delete the branch\n\nmaster\n because I am creating a branch \nnew_master\n\nwith improved/cleaned history,\nI would do the following:\n\n\ngit checkout <hash-of-commit-to-split-at>   # starting point for new branch\ngit branch new_master                       # create new branch\ngit checkout new_master                     # switch to new branch\n\n...make some commits...\n...rebase some stuff...\n...cherry pick some stuff...\n...now new branch has a long and totally different \n    commit history from master...\n\ngit push origin new_master                  # push all the new stuff to remote \"origin\"\n\ngit branch -D master                        # delete git branch master\ngit push origin :master                     # propagate deletion of branch \"master\" to remote \"origin\"\n\n\n\n\nthe third case\n\n\nIf you have an absolute clusterfuck of a commit history,\nyou need a gifted surgeon. The more gifted the surgeon,\nthe more of your repo history you'll be able to retain.\n\n\nIf you want to perform surgery with a battle axe, \nyou can simply leapfrog a whole series of complicated\nsplits, merges, rebases, and just jump to a point in \nthe repo where things are saner and calmer.\n\n\nClone a fresh copy of the repo, and checkout the \ncommit where the clusterfuck is over, when things\nare saner and calmer:\n\n\ngit checkout <commit-hash>\n\n\n\n\nNow, you're going to copy every single file\nin that folder into your current (cluster-fucked)\nrepo, exactly, word for word, character for character.\n\n\nIf you have extra files, those are okay. If you have \ndeleted files that are in the saner, calmer commit state,\nyou must add them back in.\n\n\nOnce everything matches, commit your changes.\nTag this commit as your \"Stargate\" - this is the \ncommit that will allow you to rebase from \none branch to the other. The repo will be in\nexactly the same state (with exception of extra files)\nbetween these two commits, so changes to one commit\ncan be applied to the other just fine.\n\n\nNote that you will lose all information about commits \nthat are not rebased or cherry picked, i.e., all the \ncommits that were involved with the clusterfuck.",
            "title": "Oh F&!k: Send Reinforcements"
        },
        {
            "location": "/ohfk/#oh-fk-please-send-backup",
            "text": "When you use the single-branch procedure\ninstead of the multi-branch procedure...\nthis is what happens.  Possible complications to all of this \ninclude:    Clueless individuals who do not\n    follow basic instructions and continue to push\n    old versions of the repo, which can be proactively\n    addressed by branch protection but sometimes\n    must also be retroactively dealt with;     Accidentally carrying out the procedure multiple times,\n    resulting in 2, 3, 4, even 5 copies of each commit,\n    and the duplicate commits simply refuse to die    A confusing, tangled, messy commit history that is\n    completely uninterpretable",
            "title": "Oh F&amp;!k: Please Send Backup"
        },
        {
            "location": "/ohfk/#the-first-case",
            "text": "In the first case, start by turning on branch protection,\nthen clone a fresh copy of the repository (complete with\nall the duplicate commits)",
            "title": "the first case"
        },
        {
            "location": "/ohfk/#the-second-case",
            "text": "In the second case, find the branch you want to keep,\nthen rebase or cherry pick any missing commits onto it.\nNow remove all the other branches. If these remote branches\nare not being removed, make sure you have your syntax right,\nand make sure you're using the  --force  command.  git push remote_name :branch_to_delete  For example, if I want to delete the branch master  because I am creating a branch  new_master \nwith improved/cleaned history,\nI would do the following:  git checkout <hash-of-commit-to-split-at>   # starting point for new branch\ngit branch new_master                       # create new branch\ngit checkout new_master                     # switch to new branch\n\n...make some commits...\n...rebase some stuff...\n...cherry pick some stuff...\n...now new branch has a long and totally different \n    commit history from master...\n\ngit push origin new_master                  # push all the new stuff to remote \"origin\"\n\ngit branch -D master                        # delete git branch master\ngit push origin :master                     # propagate deletion of branch \"master\" to remote \"origin\"",
            "title": "the second case"
        },
        {
            "location": "/ohfk/#the-third-case",
            "text": "If you have an absolute clusterfuck of a commit history,\nyou need a gifted surgeon. The more gifted the surgeon,\nthe more of your repo history you'll be able to retain.  If you want to perform surgery with a battle axe, \nyou can simply leapfrog a whole series of complicated\nsplits, merges, rebases, and just jump to a point in \nthe repo where things are saner and calmer.  Clone a fresh copy of the repo, and checkout the \ncommit where the clusterfuck is over, when things\nare saner and calmer:  git checkout <commit-hash>  Now, you're going to copy every single file\nin that folder into your current (cluster-fucked)\nrepo, exactly, word for word, character for character.  If you have extra files, those are okay. If you have \ndeleted files that are in the saner, calmer commit state,\nyou must add them back in.  Once everything matches, commit your changes.\nTag this commit as your \"Stargate\" - this is the \ncommit that will allow you to rebase from \none branch to the other. The repo will be in\nexactly the same state (with exception of extra files)\nbetween these two commits, so changes to one commit\ncan be applied to the other just fine.  Note that you will lose all information about commits \nthat are not rebased or cherry picked, i.e., all the \ncommits that were involved with the clusterfuck.",
            "title": "the third case"
        }
    ]
}